{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraping",
      "provenance": [],
      "authorship_tag": "ABX9TyNN+dLoPrbx20cbRt7mVKRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianoughsaid/Web-Scraping-Practice/blob/main/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhIZ18QwENYA"
      },
      "source": [
        "This is practice for webscraping. I will be finding what stocks are on the DOW 30 then finding the time series for these stocks. Lastly, I will be comparing these stocks to find what influences the movement of the DOW 30\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDcUYwo4r6Fg"
      },
      "source": [
        "# Retrieving Financial Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IarR-oLHdd"
      },
      "source": [
        "from urllib.request import urlopen\r\n",
        "url = \"https://finance.yahoo.com/quote/%5EDJI/components?p=%5EDJI\"\r\n",
        "\r\n",
        "page = urlopen(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3lb0FA3L3MY"
      },
      "source": [
        "html_bytes = page.read()\r\n",
        "html = html_bytes.decode(\"utf-8\")"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTWB8MiMORS"
      },
      "source": [
        "import re\r\n",
        "#Stores all table rows that are not the table headers into variable 'tableReferences'\r\n",
        "tableReferences = re.findall(\"<tr.*?</tr>\",html)\r\n",
        "tableReferences = tableReferences[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l_LMQmGFc4n",
        "outputId": "b54b5486-c9cb-4b3b-848e-8c83fab00894"
      },
      "source": [
        "#Finds the first two columns of table data which contain the Symbol, url suffix, and Name of the company\r\n",
        "import pandas as pd\r\n",
        "symbol = list()\r\n",
        "webSuffix = list()\r\n",
        "companyName = list()\r\n",
        "for i in tableReferences:\r\n",
        "  # symbol.append\r\n",
        "  symbol += [re.search(\"title=.\\w+\",i).group()[7:]]\r\n",
        "  webSuffix += [re.search(\"href=..*?\\\"\",i).group()[6:-1]]\r\n",
        "  companyName += [re.search(\">.*?<\",i[re.search(\"<td.*?</td>\",i).end():]).group()[1:-1]]\r\n",
        "  \r\n",
        "\r\n",
        "dow30info = pd.DataFrame(data = {'Symbol': symbol, 'Company': companyName, 'Web Suffix': webSuffix})"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Symbol                           Company        Web Suffix\n",
            "0     PG  The Procter &amp; Gamble Company    /quote/PG?p=PG\n",
            "1     KO             The Coca-Cola Company    /quote/KO?p=KO\n",
            "2    JPM          JPMorgan Chase &amp; Co.  /quote/JPM?p=JPM\n",
            "3    HON      Honeywell International Inc.  /quote/HON?p=HON\n",
            "4     VZ       Verizon Communications Inc.    /quote/VZ?p=VZ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5WX4LY8cpaM"
      },
      "source": [
        "#Finds historical information on these Companies\r\n",
        "\r\n",
        "#Build and get HTML for BeautifulSoup\r\n",
        "urlSuffix = '?period1=345427200&period2=1607904000&interval=1d&events=history&includeAdjustedClose=true'\r\n",
        "urlPrefix = 'https://query1.finance.yahoo.com/v7/finance/download/'\r\n",
        "\r\n",
        "# print(pd.read_csv(urlPrefix+dow30info.iloc[0]['Symbol']+urlSuffix))\r\n",
        "\r\n",
        "financialData = list()\r\n",
        "for i in dow30info.iterrows():\r\n",
        "  url = urlPrefix+i[1][0]+urlSuffix\r\n",
        "  financialData += [pd.read_csv(url)]\r\n",
        "\r\n",
        "print(financialData[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VreYl9gMruhA"
      },
      "source": [
        "#  Analyzing the Financial Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q067N2BsGip"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}